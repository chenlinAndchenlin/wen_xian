### 摘要

is incomplete in at least two ways

至少在两个方面是不完整的

On the one hand, current stateof-the-art ANNs appear to be too complex (e.g., now over 100 levels) compared with the relatively shallow cortical hierarchy (4-8 levels), which makes it difficult to map their elements to those in the ventral visual stream and to understand what they are doing. On the other hand, current state-of-the-art ANNs appear to be not complex enough in that they lack recurrent connections and the resulting neural response dynamics that are commonplace in the ventral visual stream

一方面，与相对较浅的皮层层次(4-8层)相比，目前最先进的人工神经网络似乎过于复杂(例如，现在超过100层)，这使得很难将它们的元素映射到腹侧视觉流中的元素并理解它们在做什么。另一方面，目前最先进的人工神经网络似乎不够复杂，因为它们缺乏循环连接和由此产生的神经反应动力学，这在腹侧视觉流中是常见的

Rather than just seeking high object recognition performance (as the state-of-the-art ANNs above), we instead try to reduce the model family to its most important elements and then gradually build new ANNs with recurrent and skip connections while monitoring both performance and the match between each new CORnet model and a large body of primate brain and behavioral data.

我们不是仅仅寻求高目标识别性能(如上所述的最先进的人工神经网络)，而是尝试将模型族减少到最重要的元素，然后逐渐构建具有循环和跳过连接的新人工神经网络，同时监控性能以及每个新CORnet模型与大量灵长类动物大脑和行为数据之间的匹配。