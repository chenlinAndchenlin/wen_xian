### 编码：

 Bagheri et al [34] studied the sensitivity of SNN w.r.t. different types of encoding, when subjected to white-box adversarial attacks.

Bagheri等[34]研究了不同编码类型的SNN w.r.t.在受到白盒对抗性攻击时的敏感性。

【34】A. Bagheri, O. Simeone, and B. Rajendran, “Adversarial training for probabilistic spiking neural networks,” in SPAWC, 2018.





Kim等人[10]在低 延迟训练中比较了两种编码的鲁棒性、能量效率、 准确性等特性。

【10】KIM Y, PARK H, MOITRA A, et al. Rate coding or direct coding: Which one is better for accurate, robust, and energy-efficient spiking neural networks?[C]. 2022 IEEE International Conference on Acoustics, Speech and Signal Processing, Singapore, 2022: 71–75. doi: 10.1109/ ICASSP43922.2022.9747906. 





### 固有结构的鲁棒性探究：

[14] A. Marchisio et al, “Is spiking secure? a comparative study on the security vulnerabilities of spiking and deep neural networks,” in IJCNN, 2020.

[15] S. Sharmin et al, “A comprehensive analysis on adversarial robustness of spiking neural networks,” in IJCNN, 2019.



### 黑盒测试DNN-SNN

Marchisio et al [14] applied black-box adversarial attacks to DNNs and SNNs, and the comparison showed that the SNNs are more robust. S

Marchisio等[14]将黑盒对抗性攻击应用于dnn和snn，对比发现snn具有更强的鲁棒性。

【14】Marchisio et al., “Is spiking secure? a comparative study on the securityvulnerabilities of spiking and deep neural networks,” in IJCNN, 2020





### 参数

The work of [36] analyzed the adversarial accuracy of SNNs trained with different inference latency and leak factor in LIF spiking neurons. However, this work did not explore the impact of membrane voltage threshold along with the time window.

Note, in contrast to the work in [36], we explore the impact of spiking parameters of the neurons on SNNs robustness to question the generalization of inherent robustness observation.

[36]的工作分析了在LIF尖峰神经元中使用不同推理延迟和泄漏因子训练的snn的对抗精度。然而，这项工作并没有探讨膜电压阈值随时间窗的影响。


注意，与[36]中的工作相反，我们探讨了神经元的峰值参数对snn鲁棒性的影响，以质E疑固有鲁棒性观察的泛化。

[36] S. Sharmin, N. Rathi, P. Panda, and K. Roy, “Inherent adversarial robustness of deep spiking neural networks: Effects of discrete input encoding and non-linear activations,” ArXiv, vol. abs/2003.10399, 2020.

本文：EL-ALLAMI R, MARCHISIO A, SHAFIQUE M, et al. Securing deep spiking neural networks against adversarial attacks through inherent structural parameters[C]. 2021 Design, Automation & Test in Europe Conference & Exhibition, Grenoble, France, 2021: 774–779. doi: 10.23919/ DATE51398.2021.9473981.